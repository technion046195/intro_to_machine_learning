{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 class=\"background-title\">Workshop 2 - Background<br>Probability & Non-Parametric Density Estimation</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/doodle/96/000000/books.png\"> Background\n",
    "\n",
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/plasticine/100/000000/slot-machine.png\"> A Random Phenomenon\n",
    "\n",
    "In most cases in machine learning, we will describe the process which generates the data as a random phenomenon. \n",
    "\n",
    "Let us have a short recap of the concepts we use to handle random phenomenons. As an example we will take a look at the following random phenomenon:\n",
    "\n",
    "> We take a glass full of juice and pure it on the floor (don't try this at home) and look at the shape of the resulting spill. \n",
    "\n",
    "Below is a table defining some of the concepts which we will be using when working with random phenomenons, along with the example of spilling the glass of juice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| name | Usually donated by | Definition | Example  |\n",
    "| :--- | --- | --- | --- |\n",
    "| **A random phenomenon**<br><br><br><br> |- | Some process which generates random outcomes |  Spilling a glass of juice on the floor and examining at the shape of the spill |\n",
    "| **A sample**<br><br><br><br> | $\\omega$ | A single outcome of the process |  Some specific spill shape |\n",
    "| **Sample space**<br><br><br><br> | $\\Omega$ | The space of all possible outcomes of the given process. $\\Omega=\\left\\{\\forall\\omega\\right\\}$ |  The space of all possible spill shapes |\n",
    "| **Random Variables**<br><br><br><br> | $X\\left(\\omega\\right)$,$Y\\left(\\omega\\right)$,... | A function $X:\\Omega\\rightarrow\\mathbb{R}$ which assigns a real number to a given sample | A function which returns the perimeter of a spill:<br>$X_1\\left(\\omega\\right)$<br>A function which returns the area of a spill:<br> $X_2\\left(\\omega\\right)$ |\n",
    "| **An event**<br><br><br><br> | $A$ | A collection of events, i.e., a subset of the sample space $A\\subseteq\\Omega$.<br>We would often define an event through a condition on random variables. |  The collection of all spills with a perimeter smaller than 2:<br>$A=\\left\\{\\omega: X_1\\left(\\omega\\right)<2 \\right\\}$<br>The collection of all spills with a area larger than 1:<br>$B=\\left\\{\\omega: X_2\\left(\\omega\\right)>1 \\right\\}$ |\n",
    "| **Event space**<br><br><br><br> | $\\mathcal{F}$ | A space of events. $A\\in\\mathcal{F}$  | The space of all possible collections of spills shape |\n",
    "| **Probability measure**<br><br><br><br> | $P\\left(A\\right)$ | A function $P:\\mathcal{F}\\rightarrow\\left[0,1\\right]$ which returns the probability of a random sample to be an element in some event $A$ | $P\\left(A\\right)=P\\left(X_1<2\\right)=0.1$<br>$P\\left(X_1<0\\right)=P\\left(\\emptyset\\right)=0$<br>$P\\left(0\\leq X_1\\right)=P\\left(\\Omega\\right)=1$<br>$P\\left(A\\cup B\\right)=P\\left(X_1<2\\ \\text{or}\\ X_2>1\\right)=0.6$<br>$P\\left(A\\cap B\\right)=P\\left(X_1<2\\ \\text{and}\\ X_2>1\\right)=0.01$ |\n",
    "| **Conditional probability measure**<br><br><br><br> | $P\\left(AÇ€B\\right)$ | A function $P:\\mathcal{F}_1\\times\\mathcal{F}_2\\rightarrow\\left[0,1\\right]$ which returns the probability of a random sample to be an element in event $A$ given that it is an element in event $B$ | The probability of a spill to have a diameter smaller than 2, given that it has a area larger than 1:<br>$P\\left(AÇ€B\\right)=P\\left(X_1<2Ç€X_2>1\\right)=0.02$ |\n",
    "\n",
    "In the last two rows we have used $X<2$ as a shorthand for $\\left\\{\\omega:X\\left(\\omega\\right)<2\\right\\}$. This is in fact a common shorthand writing and we will usually be using it from here on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<center><img src=\"../media/diagrams/random_process.png?2\" style=\"width:700px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/ultraviolet/40/000000/normal-distribution-histogram.png\"> Distributions\n",
    "\n",
    "\n",
    "\n",
    "**Realizations**: The outcomes of the random variable, i.e., the output value we get for a random outcome of the process, is called realization. We usually denote random variables by upper case letter and denote their realization using the equivalent lower case one, for example, the random variable $X$ and its realization $x$. \n",
    "\n",
    "In many cases, the term samples is used to refer to the realizations themselves without making the distinction between the actual samples and the result of the random variable operating in them.   \n",
    "\n",
    "The distribution of a random variable describes the probability of getting realizations values. The distribution is usually described by one of the following functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cumulative Distribution Function (the CDF)\n",
    "\n",
    "The CDF of a random variable $X$ is usually denoted by $F_X\\left(x\\right)$ and is defined as:\n",
    "$$\n",
    "F_{X}\\left(x\\right)=P\\left(X\\leq x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Probability Density Function (the PDF) - For a Continues Random Variable\n",
    "\n",
    "*Not the documents file format* ðŸ˜‰\n",
    "\n",
    "The PDF of a random variable $X$ is usually denoted by $f_X\\left(x\\right)$ or $p_X\\left(x\\right)$ and is defined as a function for which:\n",
    "\n",
    "$$\n",
    "F_X\\left(x\\right)=\\int_{-\\infty}^{x}p_X\\left(x\\right)dx\n",
    "$$\n",
    "\n",
    "If $F_X\\left(x\\right)$ is differentiable the:\n",
    "\n",
    "$$\n",
    "p_X\\left(x\\right)=\\frac{d}{dx}F_X\\left(x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Probability Mass Function (the PMF) - For a Discrete Random Variable\n",
    "\n",
    "The PMF of a random variable $X$ is also usually denoted by $f_X\\left(x\\right)$ or $p_X\\left(x\\right)$ and is defined as:\n",
    "\n",
    "$$\n",
    "p_X\\left(x\\right)=P\\left(X=x\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/ultraviolet/80/000000/average-math.png\"> Expectation Value\n",
    "\n",
    "In the discrete case, the expectation value of a random variable $X$ is the weighted average of the outcomes random variable can produce, where the weights are the probability assigned to each outcome, i.e., the PMF. We will denote it by $\\mathbb{E}\\left[x\\right]$. It is calculated by:\n",
    "$$\n",
    "\\mathbb{E}\\left[x\\right]=\\sum_{x\\in\\left\\{X\\left(\\omega\\right),\\omega\\in\\Omega\\right\\}} x\\cdot p_X\\left(x\\right)\n",
    "$$\n",
    "\n",
    "Where $\\left\\{X\\left(\\omega\\right),\\omega\\in\\Omega\\right\\}$ represents the space of all possible outcomes of the random variable $X$.\n",
    "\n",
    "It can be shown that the expectation value of the random variable $g\\left(X\\left(\\omega\\right)\\right)$, for any given $g$, can be calculated as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[g\\left(x\\right)\\right]=\\sum_{g\\left(x\\right)} g\\left(x\\right)\\cdot p_{g\\left(X\\right)}\\left(g\\left(x\\right)\\right)=\\sum_{x} g\\left(x\\right)\\cdot p_X\\left(x\\right)\n",
    "$$\n",
    "\n",
    "In the continues case, the expectation value is calculated by:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[g\\left(x\\right)\\right]=\\int_{-\\infty}^\\infty g\\left(x\\right)\\cdot p_X\\left(x\\right)dx\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/doodle/96/000000/tape-measure.png\"> Estimating the distribution\n",
    "\n",
    "In the context of machine learning, we would like to estimate the unknown distribution of a random variable based on a set of samples of it which we will call the dataset. **We will always assume here that the samples in the dataset are statistically independent**.\n",
    "\n",
    "We will usually denote an estimation of some value $x$ using the \"hat\" sign: $\\hat{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Measure\n",
    "\n",
    "Before evaluating distributions let us define the empirical measure and empirical mean.\n",
    "\n",
    "The empirical measure is an estimation of a probability measure given a set of samples. Using the following notation:\n",
    "\n",
    "- $N$ - the number of samples in the dataset.\n",
    "- $\\omega_i$ - the $i$-th sample.\n",
    "- $I\\left\\{\\omega_i \\in A\\right\\}$ - An indicator function of whether or not $\\omega_i$ is an element in event $A$.\n",
    "\n",
    "The empirical measure of the probability measure $P\\left(A\\right)$ is defined as:\n",
    "\n",
    "$$\n",
    "\\hat{p}_A=\\tfrac{1}{N}\\sum_{i=1}^N I\\left\\{\\omega_i\\in A\\right\\}\n",
    "$$\n",
    "\n",
    "Put in words, we estimate the probability of an event as the fraction of samples in the dataset which are members of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Mean\n",
    "\n",
    "The empirical mean is a way to estimates the value of an expectation value given a set of samples. Adding the following notation:\n",
    "\n",
    "- $x_i$ - the realization value of the $i$-th sample, i.e., $X\\left(\\omega_i\\right)$. **From here on we will refer to $X_i$ is as the $X$ value of the $i$-th sample.**\n",
    "\n",
    "The empirical mean of the expectation value $\\mathbb{E}\\left[f\\left(x\\right)\\right]$ is then defined as:\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_{f\\left(x\\right)}=\\tfrac{1}{N}\\sum_{i=1}^N f\\left(x_i\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/color/96/000000/bar-chart.png\"> Estimating the PMF\n",
    "\n",
    "We can use the empirical measure we can estimate the PMF of a random variable $X$. We shall denote:\n",
    "\n",
    "- $N$ - the number of samples in the dataset.\n",
    "- $x_i$ - the $X$ value of the $i$-th sample.\n",
    "- $I\\left\\{x_i = x\\right\\}$ - An indicator function of whether or not $x_i$ is equal to $x$.\n",
    "\n",
    "The PMF estimation of $p_{X}\\left(x\\right)$ is then given by:\n",
    "$$\n",
    "\\hat{p}_{X}\\left(x\\right)=\\tfrac{1}{N}\\sum_{i=1}^N I\\left\\{x_i = x\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/plasticine/100/000000/bullish.png\"> The Empirical Cumulative Distribution Function (the ECDF)\n",
    "\n",
    "Similarly, we can CDF of a random variable $X$. We shall denote:\n",
    "\n",
    "- $N$ - the number of samples in the dataset.\n",
    "- $x_i$ - the $X$ value of the $i$-th sample.\n",
    "- $I\\left\\{x_i \\leq x\\right\\}$ - An indicator function of whether or not $x_i$ is smaller then $x$.\n",
    "\n",
    "The ECDF estimation of the CDF $F_{X}\\left(x\\right)$ is then given by:\n",
    "$$\n",
    "\\hat{F}_{X}\\left(x\\right)=\\tfrac{1}{N}\\sum_{i=1}^N I\\left\\{x_i \\leq x\\right\\}\n",
    "$$\n",
    "\n",
    "The ECDF results in a non-continues CDF which is a sum of step functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-15T13:43:58.151631Z",
     "start_time": "2019-03-15T13:43:58.102573Z"
    }
   },
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/doodle/48/000000/bar-chart.png\"> Histogram\n",
    "\n",
    "A histogram is constructed by dividing the range of possible outcomes a random variable can take into bins and then estimating the probability density (the value of the PDF) in each bin in a manner similar to the PMF estimation. We shall denote:\n",
    "\n",
    "- $N$ the number of samples of the random variable $X$.\n",
    "- $x_i$ - the $X$ value of the $i$-th sample.\n",
    "- $l_k$, $r_k$ - The left and right edges of the $k$'s bin.\n",
    "- $I\\left\\{l_k \\leq x_i < r_k\\right\\}$ - An indicator function of whether or not $x_i$ is the $k$'s bin\n",
    "\n",
    "The histogram which estimates the PDF $p_X\\left(x\\right)$ is given by:\n",
    "$$\n",
    "h_X\\left(l_k \\leq x < r_k\\right) = \\tfrac{1}{N\\cdot\\left(r_k-l_k\\right)}\\sum_{i=1}^N I\\left\\{l_k \\leq x_i < r_k\\right\\}\n",
    "$$\n",
    "\n",
    "the additional division by $\\left(r_k-l_k\\right)$ is to produce a probability density from the estimated probability.\n",
    "\n",
    "*The actual calculation for when and how good is this approximation is outside the scope of this course.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection of the bins significantly effects how well the histogram approximates the PDF. A common thumb rule for selecting the bins is to divide the range of values into $\\sqrt{N}$ equal bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://img.icons8.com/ultraviolet/64/000000/chromatography.png\"> Kernel Density Estimation (KDE)\n",
    "\n",
    "KDE is another method for estimating the PDF. In KDE the samples are smoothed out using a smoothing function called the **Parzan window**. \n",
    "\n",
    "One way of understanding the resulting PDF is by thinking of it as a PDF which was generated by placing a Dirac delta function in each sampled value and then smoothing it out using the Parzen window.\n",
    "\n",
    "We shall denote:\n",
    "\n",
    "- $N$ the number of samples of the random variable $X$.\n",
    "- $x_i$ - the $X$ value of the $i$-th sample.\n",
    "- $\\phi\\left(x\\right)$ - the selected Parzen window.\n",
    "\n",
    "The KDE which estimates the PDF $p_X\\left(x\\right)$ is given by:\n",
    "$$\n",
    "\\hat{p}_{\\phi,X}\\left(x\\right) = \\frac{1}{N}\\sum_{i=1}^N \\phi\\left(x-x_i\\right)\n",
    "$$\n",
    "\n",
    "It is common to add a scaling factor $h$, called the bandwidth, to the Parzen window to control the width of the window. We shall denote the scaled version of the window by $\\phi_h\\left(x\\right)=\\frac{1}{h}\\phi\\left(\\frac{x}{h}\\right)$. Plugging this into the definition of the KDE, we get:\n",
    "\n",
    "$$\n",
    "\\hat{p}_{\\phi,h,X}\\left(x\\right) = \\frac{1}{N\\cdot h}\\sum_{i=1}^N \\phi\\left(\\frac{x-x_i}{h}\\right)\n",
    "$$\n",
    "\n",
    "Two common choices of the Parzen window are:\n",
    "- A Gaussian: $\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right)$\n",
    "- A rectangular function $I\\left\\{\\left|x\\right|\\leq0.5\\right\\}$\n",
    "\n",
    "A thumb rule for selecting the bandwidth for the Gaussian window is: $\\left(\\frac{4\\cdot\\text{std}\\left\\{x_i\\right\\}}{3N}\\right)^\\frac{1}{5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img style=\"display:inline;height:50px\" height=\"50px\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/3c/Cc-by_new.svg\">  Attributions\n",
    "Icons in these notebooks were made by:\n",
    "- <https://icons8.com> is licensed by  [CC 3.0 BY-ND](http://creativecommons.org/licenses/by-nd/3.0/)\n",
    "- [Freepik](https://www.freepik.com) from <https://www.flaticon.com> is licensed by [CC 3.0 BY](http://creativecommons.org/licenses/by/3.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T15:27:36.476974Z",
     "start_time": "2019-03-19T15:27:36.470303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link rel=\"stylesheet\" href=\"../css/style.css\"> <!--Setting styles - You can simply ignore this line-->\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"../css/style.css\"> <!--Setting styles - You can simply ignore this line-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
